{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ub1xOSRFMP6BrmnO4xXQF9cMS8mC14Ch",
      "authorship_tag": "ABX9TyNU/ZPLK3Y+/w1ghPSz+1aj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryan011001/3D_Portfolio/blob/main/face_morphing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Google Drive"
      ],
      "metadata": {
        "id": "WZKdCQ1rubWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "InK1YvKtRsLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ca79f1-eaa0-43a5-f3df-0a95946e58a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_path =\"/content/drive/MyDrive/Colab Notebooks/FACE_MORPHING/ArshJeetSent/rgb_data.npy\"\n",
        "labels_path=\"/content/drive/MyDrive/Colab Notebooks/FACE_MORPHING/ArshJeetSent/mask_data.npy\""
      ],
      "metadata": {
        "id": "mM-NReuQZycs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_v246QCoaiR2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the preprocessed data using numpy"
      ],
      "metadata": {
        "id": "o_mUMwauugHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_images = np.load(images_path)\n",
        "resized_masks_array = np.load(labels_path)"
      ],
      "metadata": {
        "id": "YAB4CbPXakFr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset\n"
      ],
      "metadata": {
        "id": "9iFYZPEOumMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(rgb_images, resized_masks_array, validation_split):\n",
        "  # Split data into training and validation sets\n",
        "  num_samples = len(rgb_images)\n",
        "  num_train_samples = int((1 - validation_split) * num_samples)\n",
        "\n",
        "  # Separate training and validation data\n",
        "  train_rgb_images = rgb_images[:num_train_samples]\n",
        "  train_masks = resized_masks_array[:num_train_samples]\n",
        "\n",
        "  val_rgb_images = rgb_images[num_train_samples:]\n",
        "  val_masks = resized_masks_array[num_train_samples:]\n",
        "\n",
        "  # return (train_rgb_images, train_masks), (val_rgb_images, val_masks)\n",
        "\n",
        "  train_masks = np.expand_dims(train_masks, axis=-1)  # Add channel dimension at the end\n",
        "  val_masks = np.expand_dims(val_masks, axis=-1)\n",
        "\n",
        "  return (train_rgb_images, train_masks), (val_rgb_images, val_masks)"
      ],
      "metadata": {
        "id": "JOFWIm12fwa2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_rgb_images, train_masks), (test_rgb_images, test_masks) = split_data(rgb_images, resized_masks_array, validation_split=0.1)\n",
        "(train_rgb_images, train_masks), (val_rgb_images, val_masks) = split_data(train_rgb_images, train_masks, validation_split=0.1)"
      ],
      "metadata": {
        "id": "xp_x2s4vJrA6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create datasets with masks"
      ],
      "metadata": {
        "id": "31a_QF2Vu2mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "oMXVtssjGEDe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_rgb_images, train_masks)).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_rgb_images, val_masks)).batch(1)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_rgb_images, test_masks)).batch(1)"
      ],
      "metadata": {
        "id": "ruEVcnIkmBvQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shapes of images"
      ],
      "metadata": {
        "id": "8vFnryNBQ-zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_rgb_images.shape)  # Print the shape of train_rgb_images\n",
        "print(train_masks.shape)       # Print the shape of train_masks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61_7fhy9OBIm",
        "outputId": "e9319daa-8fd7-4378-e0d1-b36f519bb319"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1932, 64, 64, 3)\n",
            "(1932, 64, 64, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, masks in train_dataset.take(1):  # Took 1 batch from the training data\n",
        "    print(images.shape)  # input images shapes\n",
        "    print(masks.shape)   # shape of the masks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQNw4dL2OaA9",
        "outputId": "5e7a25e1-c943-4620-e904-bfb774bdcc24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 64, 64, 3)\n",
            "(32, 64, 64, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for saving each epoch\n",
        "creating callbacks and checkpoints"
      ],
      "metadata": {
        "id": "rzYlhM83z0mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/FACE_MORPHING/training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights after each epoch\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')"
      ],
      "metadata": {
        "id": "BoKfcJt9z599"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture and Compiling"
      ],
      "metadata": {
        "id": "kXtN3D5YvBnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "GJbkOr6soffA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid'),\n",
        "    # tf.keras.layers.Dense(14, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')  # Output shape matches the shape of the labels\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iMr5LnPaopwm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLWkRXotZR3v",
        "outputId": "6bce84b9-efec-428f-b745-ba91c434f9a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 1)         65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19457 (76.00 KB)\n",
            "Trainable params: 19457 (76.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "ceV0xdvfZju2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(checkpoint_dir):\n",
        "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    if latest_checkpoint is not None:\n",
        "        print(\"Loading weights from\", latest_checkpoint)\n",
        "        model.load_weights(latest_checkpoint)"
      ],
      "metadata": {
        "id": "B0oPQXqGwqbG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "B-U35_sZvJh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "Qu1cpkBOGpGC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obq_QORypTsr",
        "outputId": "5fc2307a-73cc-40fc-f69a-188071d02c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 2/61 [..............................] - ETA: 31:35 - loss: 0.5596 - accuracy: 0.0138    "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "JvGMuxRU0OTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "# print(f'Test Loss: {test_loss}')\n",
        "# print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_results = model.evaluate(test_dataset)\n",
        "\n",
        "# Check if evaluation results are valid\n",
        "if evaluation_results is not None and len(evaluation_results) == 2:\n",
        "    test_loss, test_accuracy = evaluation_results\n",
        "    print(f'Test Loss: {test_loss}')\n",
        "    print(f'Test Accuracy: {test_accuracy}')\n",
        "else:\n",
        "    print(\"Error: Evaluation results are not valid or None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ07j_xztyWh",
        "outputId": "d7423c04-6ea7-4465-ab98-7a44be410892"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239/239 [==============================] - 2s 6ms/step - loss: 0.6776 - accuracy: 0.0000e+00\n",
            "Test Loss: 0.6775946617126465\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    }
  ]
}